{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural network for classification of contaminants with MAT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Formulate/outline the problem: classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Simple neural network for classification of the contaminants using MAT transcriptomes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = \"gene_counts_NN_training.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Identify inputs and outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sample</th>\n",
       "      <th>HUNK</th>\n",
       "      <th>KLHL8</th>\n",
       "      <th>ZNF576</th>\n",
       "      <th>UGT1A5</th>\n",
       "      <th>FCF1</th>\n",
       "      <th>SLC2A7</th>\n",
       "      <th>FABP12</th>\n",
       "      <th>TAF12</th>\n",
       "      <th>GLRX</th>\n",
       "      <th>...</th>\n",
       "      <th>ASIC2</th>\n",
       "      <th>TSN</th>\n",
       "      <th>EVA1A</th>\n",
       "      <th>NFATC1</th>\n",
       "      <th>PORCN</th>\n",
       "      <th>GALNT17</th>\n",
       "      <th>DEPDC4</th>\n",
       "      <th>REL</th>\n",
       "      <th>RPL23</th>\n",
       "      <th>AHSP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>R848</td>\n",
       "      <td>1.0</td>\n",
       "      <td>282.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>500.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>124.0</td>\n",
       "      <td>281.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>722.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>688.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12160.0</td>\n",
       "      <td>6042.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CRX-527</td>\n",
       "      <td>0.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>484.0</td>\n",
       "      <td>746.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CL-307</td>\n",
       "      <td>3.0</td>\n",
       "      <td>152.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>293.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>154.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>462.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>495.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4353.0</td>\n",
       "      <td>3391.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Pam3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>152.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>204.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>234.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1350.0</td>\n",
       "      <td>2014.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Pam3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>115.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>235.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>375.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>409.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3349.0</td>\n",
       "      <td>2760.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 19993 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    sample  HUNK  KLHL8  ZNF576  UGT1A5   FCF1  SLC2A7  FABP12  TAF12   GLRX  \\\n",
       "0     R848   1.0  282.0    84.0     0.0  500.0     0.0     0.0  124.0  281.0   \n",
       "1  CRX-527   0.0   35.0     5.0     0.0   63.0     0.0     0.0   14.0   20.0   \n",
       "2   CL-307   3.0  152.0    41.0     0.0  293.0     0.0     0.0   88.0  154.0   \n",
       "3     Pam3   0.0   55.0    28.0     0.0  152.0     0.0     0.0   32.0   60.0   \n",
       "4     Pam3   0.0  115.0    32.0     0.0  235.0     0.0     0.0   68.0   71.0   \n",
       "\n",
       "   ...  ASIC2    TSN  EVA1A  NFATC1  PORCN  GALNT17  DEPDC4      REL   RPL23  \\\n",
       "0  ...    0.0  722.0    0.0   688.0   45.0      0.0     0.0  12160.0  6042.0   \n",
       "1  ...    0.0   55.0    0.0    94.0    2.0      0.0     0.0    484.0   746.0   \n",
       "2  ...    0.0  462.0    0.0   495.0   38.0      0.0     0.0   4353.0  3391.0   \n",
       "3  ...    0.0  204.0    0.0   234.0   10.0      0.0     0.0   1350.0  2014.0   \n",
       "4  ...    0.0  375.0    0.0   409.0   23.0      0.0     0.0   3349.0  2760.0   \n",
       "\n",
       "   AHSP  \n",
       "0   1.0  \n",
       "1   0.0  \n",
       "2   2.0  \n",
       "3   1.0  \n",
       "4   0.0  \n",
       "\n",
       "[5 rows x 19993 columns]"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'array' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[128], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m encoding \u001b[39m=\u001b[39m array(data[\u001b[39m\"\u001b[39m\u001b[39msample\u001b[39m\u001b[39m\"\u001b[39m])\n\u001b[1;32m      2\u001b[0m encoding\u001b[39m.\u001b[39mreshape(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, \u001b[39m1\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'array' is not defined"
     ]
    }
   ],
   "source": [
    "encoding = array(data[\"sample\"])\n",
    "encoding.reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Expected 2D array, got 1D array instead:\narray=['R848' 'CRX-527' 'CL-307' 'Pam3' 'Pam3' 'CRX-527' 'Fla-PA' 'LPS' 'CL-307'\n 'CL-307' 'PGN' 'R848' 'LPS' 'IMDM' 'LTA' 'R848' 'IMDM' 'CRX-527' 'PGN'\n 'LTA' 'PGN' 'LPS' 'IMDM' 'CL-307' 'IMDM' 'R848' 'PGN' 'CRX-527' 'CRX-527'\n 'Fla-PA' 'CL-307' 'Pam3' 'LPS' 'LTA' 'R848' 'PGN' 'Pam3' 'Fla-PA' 'Pam3'\n 'IMDM' 'LPS'].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[126], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msklearn\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpreprocessing\u001b[39;00m \u001b[39mimport\u001b[39;00m OneHotEncoder\n\u001b[1;32m      2\u001b[0m enc \u001b[39m=\u001b[39m OneHotEncoder(handle_unknown\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mignore\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m----> 4\u001b[0m enc\u001b[39m.\u001b[39;49mfit(data[\u001b[39m\"\u001b[39;49m\u001b[39msample\u001b[39;49m\u001b[39m\"\u001b[39;49m])\n",
      "File \u001b[0;32m~/mambaforge/envs/MATseq/lib/python3.10/site-packages/sklearn/base.py:1151\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1144\u001b[0m     estimator\u001b[39m.\u001b[39m_validate_params()\n\u001b[1;32m   1146\u001b[0m \u001b[39mwith\u001b[39;00m config_context(\n\u001b[1;32m   1147\u001b[0m     skip_parameter_validation\u001b[39m=\u001b[39m(\n\u001b[1;32m   1148\u001b[0m         prefer_skip_nested_validation \u001b[39mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1149\u001b[0m     )\n\u001b[1;32m   1150\u001b[0m ):\n\u001b[0;32m-> 1151\u001b[0m     \u001b[39mreturn\u001b[39;00m fit_method(estimator, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/mambaforge/envs/MATseq/lib/python3.10/site-packages/sklearn/preprocessing/_encoders.py:982\u001b[0m, in \u001b[0;36mOneHotEncoder.fit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    972\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\n\u001b[1;32m    973\u001b[0m         (\n\u001b[1;32m    974\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39m`sparse` was renamed to `sparse_output` in version 1.2 and \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    978\u001b[0m         \u001b[39mFutureWarning\u001b[39;00m,\n\u001b[1;32m    979\u001b[0m     )\n\u001b[1;32m    980\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msparse_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msparse\n\u001b[0;32m--> 982\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_fit(\n\u001b[1;32m    983\u001b[0m     X,\n\u001b[1;32m    984\u001b[0m     handle_unknown\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mhandle_unknown,\n\u001b[1;32m    985\u001b[0m     force_all_finite\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mallow-nan\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m    986\u001b[0m )\n\u001b[1;32m    987\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_set_drop_idx()\n\u001b[1;32m    988\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_n_features_outs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compute_n_features_outs()\n",
      "File \u001b[0;32m~/mambaforge/envs/MATseq/lib/python3.10/site-packages/sklearn/preprocessing/_encoders.py:77\u001b[0m, in \u001b[0;36m_BaseEncoder._fit\u001b[0;34m(self, X, handle_unknown, force_all_finite, return_counts, return_and_ignore_missing_for_infrequent)\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_n_features(X, reset\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m     76\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_feature_names(X, reset\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m---> 77\u001b[0m X_list, n_samples, n_features \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_check_X(\n\u001b[1;32m     78\u001b[0m     X, force_all_finite\u001b[39m=\u001b[39;49mforce_all_finite\n\u001b[1;32m     79\u001b[0m )\n\u001b[1;32m     80\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_features_in_ \u001b[39m=\u001b[39m n_features\n\u001b[1;32m     82\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcategories \u001b[39m!=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mauto\u001b[39m\u001b[39m\"\u001b[39m:\n",
      "File \u001b[0;32m~/mambaforge/envs/MATseq/lib/python3.10/site-packages/sklearn/preprocessing/_encoders.py:43\u001b[0m, in \u001b[0;36m_BaseEncoder._check_X\u001b[0;34m(self, X, force_all_finite)\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m     31\u001b[0m \u001b[39mPerform custom check_array:\u001b[39;00m\n\u001b[1;32m     32\u001b[0m \u001b[39m- convert list of strings to object dtype\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     39\u001b[0m \n\u001b[1;32m     40\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m     41\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mhasattr\u001b[39m(X, \u001b[39m\"\u001b[39m\u001b[39miloc\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mand\u001b[39;00m \u001b[39mgetattr\u001b[39m(X, \u001b[39m\"\u001b[39m\u001b[39mndim\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m0\u001b[39m) \u001b[39m==\u001b[39m \u001b[39m2\u001b[39m):\n\u001b[1;32m     42\u001b[0m     \u001b[39m# if not a dataframe, do normal check_array validation\u001b[39;00m\n\u001b[0;32m---> 43\u001b[0m     X_temp \u001b[39m=\u001b[39m check_array(X, dtype\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m, force_all_finite\u001b[39m=\u001b[39;49mforce_all_finite)\n\u001b[1;32m     44\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mhasattr\u001b[39m(X, \u001b[39m\"\u001b[39m\u001b[39mdtype\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mand\u001b[39;00m np\u001b[39m.\u001b[39missubdtype(X_temp\u001b[39m.\u001b[39mdtype, np\u001b[39m.\u001b[39mstr_):\n\u001b[1;32m     45\u001b[0m         X \u001b[39m=\u001b[39m check_array(X, dtype\u001b[39m=\u001b[39m\u001b[39mobject\u001b[39m, force_all_finite\u001b[39m=\u001b[39mforce_all_finite)\n",
      "File \u001b[0;32m~/mambaforge/envs/MATseq/lib/python3.10/site-packages/sklearn/utils/validation.py:940\u001b[0m, in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[1;32m    938\u001b[0m     \u001b[39m# If input is 1D raise error\u001b[39;00m\n\u001b[1;32m    939\u001b[0m     \u001b[39mif\u001b[39;00m array\u001b[39m.\u001b[39mndim \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m--> 940\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    941\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mExpected 2D array, got 1D array instead:\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39marray=\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m    942\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mReshape your data either using array.reshape(-1, 1) if \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    943\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39myour data has a single feature or array.reshape(1, -1) \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    944\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mif it contains a single sample.\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(array)\n\u001b[1;32m    945\u001b[0m         )\n\u001b[1;32m    947\u001b[0m \u001b[39mif\u001b[39;00m dtype_numeric \u001b[39mand\u001b[39;00m \u001b[39mhasattr\u001b[39m(array\u001b[39m.\u001b[39mdtype, \u001b[39m\"\u001b[39m\u001b[39mkind\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mand\u001b[39;00m array\u001b[39m.\u001b[39mdtype\u001b[39m.\u001b[39mkind \u001b[39min\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mUSV\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m    948\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    949\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mdtype=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mnumeric\u001b[39m\u001b[39m'\u001b[39m\u001b[39m is not compatible with arrays of bytes/strings.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    950\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mConvert your data to numeric values explicitly instead.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    951\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: Expected 2D array, got 1D array instead:\narray=['R848' 'CRX-527' 'CL-307' 'Pam3' 'Pam3' 'CRX-527' 'Fla-PA' 'LPS' 'CL-307'\n 'CL-307' 'PGN' 'R848' 'LPS' 'IMDM' 'LTA' 'R848' 'IMDM' 'CRX-527' 'PGN'\n 'LTA' 'PGN' 'LPS' 'IMDM' 'CL-307' 'IMDM' 'R848' 'PGN' 'CRX-527' 'CRX-527'\n 'Fla-PA' 'CL-307' 'Pam3' 'LPS' 'LTA' 'R848' 'PGN' 'Pam3' 'Fla-PA' 'Pam3'\n 'IMDM' 'LPS'].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample."
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "enc = OneHotEncoder(handle_unknown=\"ignore\")\n",
    "\n",
    "enc.fit(data[\"sample\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CL-307</th>\n",
       "      <th>CRX-527</th>\n",
       "      <th>Fla-PA</th>\n",
       "      <th>IMDM</th>\n",
       "      <th>LPS</th>\n",
       "      <th>LTA</th>\n",
       "      <th>PGN</th>\n",
       "      <th>Pam3</th>\n",
       "      <th>R848</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   CL-307  CRX-527  Fla-PA  IMDM  LPS  LTA  PGN  Pam3  R848\n",
       "0       0        0       0     0    0    0    0     0     1\n",
       "1       0        1       0     0    0    0    0     0     0\n",
       "2       1        0       0     0    0    0    0     0     0\n",
       "3       0        0       0     0    0    0    0     1     0\n",
       "4       0        0       0     0    0    0    0     1     0"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target = pd.get_dummies(data[\"sample\"], dtype=int)\n",
    "target.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_features = data.drop(columns=[\"sample\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    data_features, target, test_size=0.2, random_state=0, shuffle=True, stratify=target\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = to_categorical(y_train, num_classes=9)\n",
    "y_test = to_categorical(y_test, num_classes=9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((32, 9, 9), (9, 9, 9))"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "def to_normalize_DESeq2_style(data):\n",
    "    # Ensure all values are non-negative\n",
    "    data = data.applymap(lambda x: max(x, 0))\n",
    "\n",
    "    # Take the log\n",
    "    log_data = np.log1p(data)\n",
    "\n",
    "    # Calculate the pseudo-reference sample for each gene\n",
    "    log_data[\"pseudo_reference\"] = log_data.mean(axis=1)\n",
    "\n",
    "    # Filter out genes with -Inf as their average\n",
    "    filtered_log_data = log_data[log_data[\"pseudo_reference\"] != float(\"-inf\")]\n",
    "\n",
    "    # Subtract the gene pseudo-references from log counts\n",
    "    ratio_data = filtered_log_data.iloc[:, :-1].sub(\n",
    "        filtered_log_data[\"pseudo_reference\"], axis=0\n",
    "    )\n",
    "\n",
    "    # Find the median of the ratios for each sample\n",
    "    sample_medians = ratio_data.median(axis=0)\n",
    "\n",
    "    # Convert medians to scaling factors\n",
    "    scaling_factors = np.exp(sample_medians)\n",
    "\n",
    "    # Divide the original counts by the scaling factors\n",
    "    manually_normalized = data.div(scaling_factors)\n",
    "\n",
    "    return manually_normalized\n",
    "\n",
    "\n",
    "X_train = to_normalize_DESeq2_style(X_train)\n",
    "\n",
    "X_test = to_normalize_DESeq2_style(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Build an architecture from scratch or choose a pretrained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()\n",
    "keras.utils.set_random_seed(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"small_NN\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_3 (InputLayer)        [(None, 19992)]           0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 10)                199930    \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 9)                 99        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 200,029\n",
      "Trainable params: 200,029\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# create our model\n",
    "def create_nn():\n",
    "    inputs = keras.Input(shape=X_train.shape[1])\n",
    "    x = keras.layers.Dense(10, activation=\"relu\")(inputs)\n",
    "    outputs = keras.layers.Dense(9, activation=\"softmax\")(x)\n",
    "\n",
    "    model = keras.Model(inputs=inputs, outputs=outputs, name=\"small_NN\")\n",
    "    return model\n",
    "\n",
    "\n",
    "model = create_nn()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Choose a loss function and optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compile_model(model):\n",
    "    model.compile(\n",
    "        optimizer=\"adam\",\n",
    "        loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "        metrics=[keras.metrics.RootMeanSquaredError()],\n",
    "    )\n",
    "\n",
    "\n",
    "compile_model(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=\"adam\", loss=keras.losses.CategoricalCrossentropy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compile_model(model):\n",
    "    model.compile(\n",
    "        optimizer=\"adam\",\n",
    "        loss=CategoricalCrossentropy(from_logits=True),\n",
    "        metrics=[\"accuracy\"],\n",
    "    )\n",
    "\n",
    "\n",
    "compile_model(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"/home/t.afanasyeva/mambaforge/envs/MATseq/lib/python3.10/site-packages/keras/engine/training.py\", line 1284, in train_function  *\n        return step_function(self, iterator)\n    File \"/home/t.afanasyeva/mambaforge/envs/MATseq/lib/python3.10/site-packages/keras/engine/training.py\", line 1268, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/home/t.afanasyeva/mambaforge/envs/MATseq/lib/python3.10/site-packages/keras/engine/training.py\", line 1249, in run_step  **\n        outputs = model.train_step(data)\n    File \"/home/t.afanasyeva/mambaforge/envs/MATseq/lib/python3.10/site-packages/keras/engine/training.py\", line 1051, in train_step\n        loss = self.compute_loss(x, y, y_pred, sample_weight)\n    File \"/home/t.afanasyeva/mambaforge/envs/MATseq/lib/python3.10/site-packages/keras/engine/training.py\", line 1109, in compute_loss\n        return self.compiled_loss(\n    File \"/home/t.afanasyeva/mambaforge/envs/MATseq/lib/python3.10/site-packages/keras/engine/compile_utils.py\", line 265, in __call__\n        loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    File \"/home/t.afanasyeva/mambaforge/envs/MATseq/lib/python3.10/site-packages/keras/losses.py\", line 142, in __call__\n        losses = call_fn(y_true, y_pred)\n    File \"/home/t.afanasyeva/mambaforge/envs/MATseq/lib/python3.10/site-packages/keras/losses.py\", line 268, in call  **\n        return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    File \"/home/t.afanasyeva/mambaforge/envs/MATseq/lib/python3.10/site-packages/keras/losses.py\", line 1984, in categorical_crossentropy\n        return backend.categorical_crossentropy(\n    File \"/home/t.afanasyeva/mambaforge/envs/MATseq/lib/python3.10/site-packages/keras/backend.py\", line 5559, in categorical_crossentropy\n        target.shape.assert_is_compatible_with(output.shape)\n\n    ValueError: Shapes (32, 9, 9) and (32, 9) are incompatible\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[117], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m history \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mfit(X_train, y_train, epochs\u001b[39m=\u001b[39;49m\u001b[39m10\u001b[39;49m,\n\u001b[1;32m      2\u001b[0m                     validation_data\u001b[39m=\u001b[39;49m(X_test, y_test))\n",
      "File \u001b[0;32m~/mambaforge/envs/MATseq/lib/python3.10/site-packages/keras/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[39m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[39m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m/tmp/__autograph_generated_filenygxsk_3.py:15\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__train_function\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     14\u001b[0m     do_return \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m     retval_ \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39mconverted_call(ag__\u001b[39m.\u001b[39mld(step_function), (ag__\u001b[39m.\u001b[39mld(\u001b[39mself\u001b[39m), ag__\u001b[39m.\u001b[39mld(iterator)), \u001b[39mNone\u001b[39;00m, fscope)\n\u001b[1;32m     16\u001b[0m \u001b[39mexcept\u001b[39;00m:\n\u001b[1;32m     17\u001b[0m     do_return \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    File \"/home/t.afanasyeva/mambaforge/envs/MATseq/lib/python3.10/site-packages/keras/engine/training.py\", line 1284, in train_function  *\n        return step_function(self, iterator)\n    File \"/home/t.afanasyeva/mambaforge/envs/MATseq/lib/python3.10/site-packages/keras/engine/training.py\", line 1268, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/home/t.afanasyeva/mambaforge/envs/MATseq/lib/python3.10/site-packages/keras/engine/training.py\", line 1249, in run_step  **\n        outputs = model.train_step(data)\n    File \"/home/t.afanasyeva/mambaforge/envs/MATseq/lib/python3.10/site-packages/keras/engine/training.py\", line 1051, in train_step\n        loss = self.compute_loss(x, y, y_pred, sample_weight)\n    File \"/home/t.afanasyeva/mambaforge/envs/MATseq/lib/python3.10/site-packages/keras/engine/training.py\", line 1109, in compute_loss\n        return self.compiled_loss(\n    File \"/home/t.afanasyeva/mambaforge/envs/MATseq/lib/python3.10/site-packages/keras/engine/compile_utils.py\", line 265, in __call__\n        loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    File \"/home/t.afanasyeva/mambaforge/envs/MATseq/lib/python3.10/site-packages/keras/losses.py\", line 142, in __call__\n        losses = call_fn(y_true, y_pred)\n    File \"/home/t.afanasyeva/mambaforge/envs/MATseq/lib/python3.10/site-packages/keras/losses.py\", line 268, in call  **\n        return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    File \"/home/t.afanasyeva/mambaforge/envs/MATseq/lib/python3.10/site-packages/keras/losses.py\", line 1984, in categorical_crossentropy\n        return backend.categorical_crossentropy(\n    File \"/home/t.afanasyeva/mambaforge/envs/MATseq/lib/python3.10/site-packages/keras/backend.py\", line 5559, in categorical_crossentropy\n        target.shape.assert_is_compatible_with(output.shape)\n\n    ValueError: Shapes (32, 9, 9) and (32, 9) are incompatible\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, epochs=10, validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Measure performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_history(history, metrics):\n",
    "    history_df = pd.DataFrame.from_dict(history.history)\n",
    "    sns.lineplot(data=history_df[metrics])\n",
    "    plt.xlabel(\"epochs\")\n",
    "    plt.ylabel(\"metric\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"None of [Index(['accuracy', 'val_accuracy'], dtype='object')] are in the [columns]\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[92], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m plot_history(history, [\u001b[39m'\u001b[39;49m\u001b[39maccuracy\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39mval_accuracy\u001b[39;49m\u001b[39m'\u001b[39;49m])\n",
      "Cell \u001b[0;32mIn[91], line 3\u001b[0m, in \u001b[0;36mplot_history\u001b[0;34m(history, metrics)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mplot_history\u001b[39m(history, metrics):\n\u001b[1;32m      2\u001b[0m     history_df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mDataFrame\u001b[39m.\u001b[39mfrom_dict(history\u001b[39m.\u001b[39mhistory)\n\u001b[0;32m----> 3\u001b[0m     sns\u001b[39m.\u001b[39mlineplot(data\u001b[39m=\u001b[39mhistory_df[metrics])\n\u001b[1;32m      4\u001b[0m     plt\u001b[39m.\u001b[39mxlabel(\u001b[39m\"\u001b[39m\u001b[39mepochs\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m      5\u001b[0m     plt\u001b[39m.\u001b[39mylabel(\u001b[39m\"\u001b[39m\u001b[39mmetric\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/mambaforge/envs/MATseq/lib/python3.10/site-packages/pandas/core/frame.py:3767\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3765\u001b[0m     \u001b[39mif\u001b[39;00m is_iterator(key):\n\u001b[1;32m   3766\u001b[0m         key \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(key)\n\u001b[0;32m-> 3767\u001b[0m     indexer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcolumns\u001b[39m.\u001b[39;49m_get_indexer_strict(key, \u001b[39m\"\u001b[39;49m\u001b[39mcolumns\u001b[39;49m\u001b[39m\"\u001b[39;49m)[\u001b[39m1\u001b[39m]\n\u001b[1;32m   3769\u001b[0m \u001b[39m# take() does not accept boolean indexers\u001b[39;00m\n\u001b[1;32m   3770\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mgetattr\u001b[39m(indexer, \u001b[39m\"\u001b[39m\u001b[39mdtype\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m) \u001b[39m==\u001b[39m \u001b[39mbool\u001b[39m:\n",
      "File \u001b[0;32m~/mambaforge/envs/MATseq/lib/python3.10/site-packages/pandas/core/indexes/base.py:5877\u001b[0m, in \u001b[0;36mIndex._get_indexer_strict\u001b[0;34m(self, key, axis_name)\u001b[0m\n\u001b[1;32m   5874\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   5875\u001b[0m     keyarr, indexer, new_indexer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reindex_non_unique(keyarr)\n\u001b[0;32m-> 5877\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_raise_if_missing(keyarr, indexer, axis_name)\n\u001b[1;32m   5879\u001b[0m keyarr \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtake(indexer)\n\u001b[1;32m   5880\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(key, Index):\n\u001b[1;32m   5881\u001b[0m     \u001b[39m# GH 42790 - Preserve name from an Index\u001b[39;00m\n",
      "File \u001b[0;32m~/mambaforge/envs/MATseq/lib/python3.10/site-packages/pandas/core/indexes/base.py:5938\u001b[0m, in \u001b[0;36mIndex._raise_if_missing\u001b[0;34m(self, key, indexer, axis_name)\u001b[0m\n\u001b[1;32m   5936\u001b[0m     \u001b[39mif\u001b[39;00m use_interval_msg:\n\u001b[1;32m   5937\u001b[0m         key \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(key)\n\u001b[0;32m-> 5938\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mNone of [\u001b[39m\u001b[39m{\u001b[39;00mkey\u001b[39m}\u001b[39;00m\u001b[39m] are in the [\u001b[39m\u001b[39m{\u001b[39;00maxis_name\u001b[39m}\u001b[39;00m\u001b[39m]\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m   5940\u001b[0m not_found \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(ensure_index(key)[missing_mask\u001b[39m.\u001b[39mnonzero()[\u001b[39m0\u001b[39m]]\u001b[39m.\u001b[39munique())\n\u001b[1;32m   5941\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mnot_found\u001b[39m}\u001b[39;00m\u001b[39m not in index\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[0;31mKeyError\u001b[0m: \"None of [Index(['accuracy', 'val_accuracy'], dtype='object')] are in the [columns]\""
     ]
    }
   ],
   "source": [
    "plot_history(history, [\"accuracy\", \"val_accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_history(history, [\"loss\", \"val_loss\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MATseq",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
