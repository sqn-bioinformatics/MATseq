
2023-08-29 17:01:12.313089: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13775 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:3b:00.0, compute capability: 7.5
Model: "small_NN"
_________________________________________________________________
 Layer (type)                Output Shape              Param #
=================================================================
 input_1 (InputLayer)        [(None, 500)]             0
 unit_normalization (UnitNo  (None, 500)               0
 rmalization)
 dropout (Dropout)           (None, 500)               0
 dense (Dense)               (None, 256)               128256
 batch_normalization (Batch  (None, 256)               1024
 Normalization)
 dropout_1 (Dropout)         (None, 256)               0
 dense_1 (Dense)             (None, 128)               32896
 dropout_2 (Dropout)         (None, 128)               0
 dense_2 (Dense)             (None, 9)                 1161
=================================================================
Total params: 163337 (638.04 KB)
Trainable params: 162825 (636.04 KB)
Non-trainable params: 512 (2.00 KB)
_________________________________________________________________
[34m[1mwandb[39m[22m: [33mWARNING[39m The save_model argument by default saves the model in the HDF5 format that cannot save custom objects like subclassed models and custom layers. This behavior will be deprecated in a future release in favor of the SavedModel format. Meanwhile, the HDF5 model is saved as W&B files and the SavedModel as W&B Artifacts.
2023-08-29 17:01:21.629374: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x559b1a95d060 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2023-08-29 17:01:21.629407: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla T4, Compute Capability 7.5
2023-08-29 17:01:21.633987: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:255] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.
2023-08-29 17:01:21.643305: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:437] Could not create cudnn handle: CUDNN_STATUS_NOT_INITIALIZED
2023-08-29 17:01:21.643385: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:441] Memory usage: 865861632 bytes free, 15843721216 bytes total.
2023-08-29 17:01:21.643422: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:451] Possibly insufficient driver version: 495.29.5
2023-08-29 17:01:21.644206: W tensorflow/core/framework/op_kernel.cc:1828] OP_REQUIRES failed at xla_ops.cc:503 : FAILED_PRECONDITION: DNN library initialization failed. Look at the errors above for more details.
2023-08-29 17:01:21.653632: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:437] Could not create cudnn handle: CUDNN_STATUS_NOT_INITIALIZED
2023-08-29 17:01:21.653689: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:441] Memory usage: 865861632 bytes free, 15843721216 bytes total.
2023-08-29 17:01:21.653720: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:451] Possibly insufficient driver version: 495.29.5
2023-08-29 17:01:21.654337: W tensorflow/core/framework/op_kernel.cc:1828] OP_REQUIRES failed at xla_ops.cc:503 : FAILED_PRECONDITION: DNN library initialization failed. Look at the errors above for more details.
2023-08-29 17:01:21.663749: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:437] Could not create cudnn handle: CUDNN_STATUS_NOT_INITIALIZED
2023-08-29 17:01:21.663817: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:441] Memory usage: 865861632 bytes free, 15843721216 bytes total.
2023-08-29 17:01:21.663846: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:451] Possibly insufficient driver version: 495.29.5
2023-08-29 17:01:21.664454: W tensorflow/core/framework/op_kernel.cc:1828] OP_REQUIRES failed at xla_ops.cc:503 : FAILED_PRECONDITION: DNN library initialization failed. Look at the errors above for more details.
2023-08-29 17:01:21.672941: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:437] Could not create cudnn handle: CUDNN_STATUS_NOT_INITIALIZED
2023-08-29 17:01:21.673023: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:441] Memory usage: 865861632 bytes free, 15843721216 bytes total.
2023-08-29 17:01:21.673049: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:451] Possibly insufficient driver version: 495.29.5
2023-08-29 17:01:21.673646: W tensorflow/core/framework/op_kernel.cc:1828] OP_REQUIRES failed at xla_ops.cc:503 : FAILED_PRECONDITION: DNN library initialization failed. Look at the errors above for more details.
2023-08-29 17:01:21.682460: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:437] Could not create cudnn handle: CUDNN_STATUS_NOT_INITIALIZED
2023-08-29 17:01:21.682526: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:441] Memory usage: 865861632 bytes free, 15843721216 bytes total.
2023-08-29 17:01:21.682551: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:451] Possibly insufficient driver version: 495.29.5
2023-08-29 17:01:21.683158: W tensorflow/core/framework/op_kernel.cc:1828] OP_REQUIRES failed at xla_ops.cc:503 : FAILED_PRECONDITION: DNN library initialization failed. Look at the errors above for more details.
2023-08-29 17:01:21.691816: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:437] Could not create cudnn handle: CUDNN_STATUS_NOT_INITIALIZED
2023-08-29 17:01:21.691882: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:441] Memory usage: 865861632 bytes free, 15843721216 bytes total.
2023-08-29 17:01:21.691906: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:451] Possibly insufficient driver version: 495.29.5
2023-08-29 17:01:21.692507: W tensorflow/core/framework/op_kernel.cc:1828] OP_REQUIRES failed at xla_ops.cc:503 : FAILED_PRECONDITION: DNN library initialization failed. Look at the errors above for more details.
2023-08-29 17:01:21.701445: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:437] Could not create cudnn handle: CUDNN_STATUS_NOT_INITIALIZED
2023-08-29 17:01:21.701494: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:441] Memory usage: 865861632 bytes free, 15843721216 bytes total.
2023-08-29 17:01:21.701518: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:451] Possibly insufficient driver version: 495.29.5
2023-08-29 17:01:21.702121: W tensorflow/core/framework/op_kernel.cc:1828] OP_REQUIRES failed at xla_ops.cc:503 : FAILED_PRECONDITION: DNN library initialization failed. Look at the errors above for more details.
2023-08-29 17:01:21.710584: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:437] Could not create cudnn handle: CUDNN_STATUS_NOT_INITIALIZED
2023-08-29 17:01:21.710633: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:441] Memory usage: 865861632 bytes free, 15843721216 bytes total.
2023-08-29 17:01:21.710657: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:451] Possibly insufficient driver version: 495.29.5
2023-08-29 17:01:21.711260: W tensorflow/core/framework/op_kernel.cc:1828] OP_REQUIRES failed at xla_ops.cc:503 : FAILED_PRECONDITION: DNN library initialization failed. Look at the errors above for more details.
Epoch 1/300
2023-08-29 17:03:53.900966: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:437] Could not create cudnn handle: CUDNN_STATUS_NOT_INITIALIZED
2023-08-29 17:03:53.901066: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:441] Memory usage: 865861632 bytes free, 15843721216 bytes total.
2023-08-29 17:03:53.901104: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:451] Possibly insufficient driver version: 495.29.5
2023-08-29 17:03:53.901848: W tensorflow/core/framework/op_kernel.cc:1828] OP_REQUIRES failed at xla_ops.cc:503 : FAILED_PRECONDITION: DNN library initialization failed. Look at the errors above for more details.
2023-08-29 17:03:53.910672: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:437] Could not create cudnn handle: CUDNN_STATUS_NOT_INITIALIZED
2023-08-29 17:03:53.910732: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:441] Memory usage: 865861632 bytes free, 15843721216 bytes total.
2023-08-29 17:03:53.910764: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:451] Possibly insufficient driver version: 495.29.5
2023-08-29 17:03:53.911378: W tensorflow/core/framework/op_kernel.cc:1828] OP_REQUIRES failed at xla_ops.cc:503 : FAILED_PRECONDITION: DNN library initialization failed. Look at the errors above for more details.
2023-08-29 17:03:53.920253: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:437] Could not create cudnn handle: CUDNN_STATUS_NOT_INITIALIZED
2023-08-29 17:03:53.920313: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:441] Memory usage: 865861632 bytes free, 15843721216 bytes total.
2023-08-29 17:03:53.920342: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:451] Possibly insufficient driver version: 495.29.5
2023-08-29 17:03:53.920945: W tensorflow/core/framework/op_kernel.cc:1828] OP_REQUIRES failed at xla_ops.cc:503 : FAILED_PRECONDITION: DNN library initialization failed. Look at the errors above for more details.
2023-08-29 17:03:53.929537: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:437] Could not create cudnn handle: CUDNN_STATUS_NOT_INITIALIZED
2023-08-29 17:03:53.929598: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:441] Memory usage: 865861632 bytes free, 15843721216 bytes total.
2023-08-29 17:03:53.929627: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:451] Possibly insufficient driver version: 495.29.5
2023-08-29 17:03:53.930214: W tensorflow/core/framework/op_kernel.cc:1828] OP_REQUIRES failed at xla_ops.cc:503 : FAILED_PRECONDITION: DNN library initialization failed. Look at the errors above for more details.
2023-08-29 17:03:53.938814: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:437] Could not create cudnn handle: CUDNN_STATUS_NOT_INITIALIZED
2023-08-29 17:03:53.938885: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:441] Memory usage: 865861632 bytes free, 15843721216 bytes total.
2023-08-29 17:03:53.938912: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:451] Possibly insufficient driver version: 495.29.5
2023-08-29 17:03:53.939491: W tensorflow/core/framework/op_kernel.cc:1828] OP_REQUIRES failed at xla_ops.cc:503 : FAILED_PRECONDITION: DNN library initialization failed. Look at the errors above for more details.
2023-08-29 17:03:53.948022: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:437] Could not create cudnn handle: CUDNN_STATUS_NOT_INITIALIZED
2023-08-29 17:03:53.948074: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:441] Memory usage: 865861632 bytes free, 15843721216 bytes total.
2023-08-29 17:03:53.948099: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:451] Possibly insufficient driver version: 495.29.5
2023-08-29 17:03:53.948686: W tensorflow/core/framework/op_kernel.cc:1828] OP_REQUIRES failed at xla_ops.cc:503 : FAILED_PRECONDITION: DNN library initialization failed. Look at the errors above for more details.
2023-08-29 17:03:53.957181: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:437] Could not create cudnn handle: CUDNN_STATUS_NOT_INITIALIZED
2023-08-29 17:03:53.957233: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:441] Memory usage: 865861632 bytes free, 15843721216 bytes total.
2023-08-29 17:03:53.957258: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:451] Possibly insufficient driver version: 495.29.5
2023-08-29 17:03:53.957840: W tensorflow/core/framework/op_kernel.cc:1828] OP_REQUIRES failed at xla_ops.cc:503 : FAILED_PRECONDITION: DNN library initialization failed. Look at the errors above for more details.
2023-08-29 17:03:53.966086: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:437] Could not create cudnn handle: CUDNN_STATUS_NOT_INITIALIZED
2023-08-29 17:03:53.966136: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:441] Memory usage: 865861632 bytes free, 15843721216 bytes total.
2023-08-29 17:03:53.966161: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:451] Possibly insufficient driver version: 495.29.5
2023-08-29 17:03:53.966729: W tensorflow/core/framework/op_kernel.cc:1828] OP_REQUIRES failed at xla_ops.cc:503 : FAILED_PRECONDITION: DNN library initialization failed. Look at the errors above for more details.
Epoch 1/300
[name: "/device:CPU:0"
device_type: "CPU"
memory_limit: 268435456
locality {
}
incarnation: 18150657938403130067
xla_global_id: -1
, name: "/device:GPU:0"
device_type: "GPU"
memory_limit: 14444920832
locality {
  bus_id: 1
  links {
  }
}
incarnation: 10882066471675407007
physical_device_desc: "device: 0, name: Tesla T4, pci bus id: 0000:3b:00.0, compute capability: 7.5"
xla_global_id: 416903419
]
2023-08-29 17:04:20.857602: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /device:GPU:0 with 13775 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:3b:00.0, compute capability: 7.5
[name: "/device:CPU:0"
device_type: "CPU"
memory_limit: 268435456
locality {
}
incarnation: 7512699402806798714
xla_global_id: -1
, name: "/device:GPU:0"
device_type: "GPU"
memory_limit: 14444920832
locality {
  bus_id: 1
  links {
  }
}
incarnation: 14776198097286753651
physical_device_desc: "device: 0, name: Tesla T4, pci bus id: 0000:3b:00.0, compute capability: 7.5"
xla_global_id: 416903419
]
2023-08-29 17:04:54.624957: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /device:GPU:0 with 13775 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:3b:00.0, compute capability: 7.5
Epoch 1/300
2023-08-29 17:06:40.935357: W tensorflow/core/framework/op_kernel.cc:1828] OP_REQUIRES failed at xla_ops.cc:444 : INVALID_ARGUMENT: Trying to access resource Resource-9-at-0x559b1a8ae8b0 (defined @ /home/t.afanasyeva/mambaforge/envs/MATseq/lib/python3.10/site-packages/keras/src/engine/base_layer_utils.py:137) located in device /job:localhost/replica:0/task:0/device:GPU:0 from device /job:localhost/replica:0/task:0/device:CPU:0
 Cf. https://www.tensorflow.org/xla/known_issues#tfvariable_on_a_different_device
2023-08-29 17:06:40.935423: W tensorflow/core/framework/op_kernel.cc:1828] OP_REQUIRES failed at xla_ops.cc:444 : INVALID_ARGUMENT: Trying to access resource Resource-8-at-0x559b1a8a0360 (defined @ /home/t.afanasyeva/mambaforge/envs/MATseq/lib/python3.10/site-packages/keras/src/engine/base_layer_utils.py:137) located in device /job:localhost/replica:0/task:0/device:GPU:0 from device /job:localhost/replica:0/task:0/device:CPU:0
 Cf. https://www.tensorflow.org/xla/known_issues#tfvariable_on_a_different_device
2023-08-29 17:06:40.935476: I tensorflow/core/framework/local_rendezvous.cc:405] Local rendezvous recv item cancelled. Key hash: 14268743461844673415
2023-08-29 17:06:40.935498: I tensorflow/core/framework/local_rendezvous.cc:405] Local rendezvous recv item cancelled. Key hash: 17499886087757547399
2023-08-29 17:06:40.935520: I tensorflow/core/framework/local_rendezvous.cc:405] Local rendezvous recv item cancelled. Key hash: 10745376870294702285
2023-08-29 17:06:40.935531: I tensorflow/core/framework/local_rendezvous.cc:405] Local rendezvous recv item cancelled. Key hash: 6531355946136644935
2023-08-29 17:06:40.935542: I tensorflow/core/framework/local_rendezvous.cc:405] Local rendezvous recv item cancelled. Key hash: 2340169675486940707
2023-08-29 17:06:40.935552: I tensorflow/core/framework/local_rendezvous.cc:405] Local rendezvous recv item cancelled. Key hash: 3498698027515867171
2023-08-29 17:06:40.935563: I tensorflow/core/framework/local_rendezvous.cc:405] Local rendezvous recv item cancelled. Key hash: 12559774104711919205
2023-08-29 17:06:40.935575: I tensorflow/core/framework/local_rendezvous.cc:405] Local rendezvous recv item cancelled. Key hash: 5826925339922921157
2023-08-29 17:06:40.935585: I tensorflow/core/framework/local_rendezvous.cc:405] Local rendezvous recv item cancelled. Key hash: 14388449430807607913
2023-08-29 17:06:40.935604: I tensorflow/core/framework/local_rendezvous.cc:405] Local rendezvous recv item cancelled. Key hash: 8476623530493763960
2023-08-29 17:06:40.935614: I tensorflow/core/framework/local_rendezvous.cc:405] Local rendezvous recv item cancelled. Key hash: 8720675571197485604
2023-08-29 17:06:40.935630: I tensorflow/core/framework/local_rendezvous.cc:405] Local rendezvous recv item cancelled. Key hash: 16264446178261107928
2023-08-29 17:06:40.935641: I tensorflow/core/framework/local_rendezvous.cc:405] Local rendezvous recv item cancelled. Key hash: 11469251718854600220
2023-08-29 17:06:40.935651: I tensorflow/core/framework/local_rendezvous.cc:405] Local rendezvous recv item cancelled. Key hash: 14850970556316706602
2023-08-29 17:06:40.935670: I tensorflow/core/framework/local_rendezvous.cc:405] Local rendezvous recv item cancelled. Key hash: 2124938208753503804
2023-08-29 17:06:40.935680: I tensorflow/core/framework/local_rendezvous.cc:405] Local rendezvous recv item cancelled. Key hash: 5278890927702326000
2023-08-29 17:06:40.935706: I tensorflow/core/framework/local_rendezvous.cc:405] Local rendezvous recv item cancelled. Key hash: 6883043726355332258
2023-08-29 17:06:40.935717: I tensorflow/core/framework/local_rendezvous.cc:405] Local rendezvous recv item cancelled. Key hash: 17498259851160682274
2023-08-29 17:06:40.935840: W tensorflow/core/framework/op_kernel.cc:1828] OP_REQUIRES failed at xla_ops.cc:444 : INVALID_ARGUMENT: Trying to access resource Resource-2-at-0x559b1a831260 (defined @ /home/t.afanasyeva/mambaforge/envs/MATseq/lib/python3.10/site-packages/keras/src/engine/base_layer_utils.py:137) located in device /job:localhost/replica:0/task:0/device:GPU:0 from device /job:localhost/replica:0/task:0/device:CPU:0
 Cf. https://www.tensorflow.org/xla/known_issues#tfvariable_on_a_different_device
2023-08-29 17:06:40.936208: W tensorflow/core/framework/op_kernel.cc:1828] OP_REQUIRES failed at xla_ops.cc:444 : INVALID_ARGUMENT: Trying to access resource Resource-6-at-0x559b1a834fc0 (defined @ /home/t.afanasyeva/mambaforge/envs/MATseq/lib/python3.10/site-packages/keras/src/engine/base_layer_utils.py:137) located in device /job:localhost/replica:0/task:0/device:GPU:0 from device /job:localhost/replica:0/task:0/device:CPU:0
 Cf. https://www.tensorflow.org/xla/known_issues#tfvariable_on_a_different_device
2023-08-29 17:06:40.936257: W tensorflow/core/framework/op_kernel.cc:1828] OP_REQUIRES failed at xla_ops.cc:444 : INVALID_ARGUMENT: Trying to access resource Resource-7-at-0x559b1a844ef0 (defined @ /home/t.afanasyeva/mambaforge/envs/MATseq/lib/python3.10/site-packages/keras/src/engine/base_layer_utils.py:137) located in device /job:localhost/replica:0/task:0/device:GPU:0 from device /job:localhost/replica:0/task:0/device:CPU:0
 Cf. https://www.tensorflow.org/xla/known_issues#tfvariable_on_a_different_device
2023-08-29 17:06:40.936283: W tensorflow/core/framework/op_kernel.cc:1828] OP_REQUIRES failed at xla_ops.cc:444 : INVALID_ARGUMENT: Trying to access resource Resource-1-at-0x559b1a7e08b0 (defined @ /home/t.afanasyeva/mambaforge/envs/MATseq/lib/python3.10/site-packages/keras/src/engine/base_layer_utils.py:137) located in device /job:localhost/replica:0/task:0/device:GPU:0 from device /job:localhost/replica:0/task:0/device:CPU:0
 Cf. https://www.tensorflow.org/xla/known_issues#tfvariable_on_a_different_device
2023-08-29 17:06:40.936336: W tensorflow/core/framework/op_kernel.cc:1828] OP_REQUIRES failed at xla_ops.cc:444 : INVALID_ARGUMENT: Trying to access resource Resource-3-at-0x559b1a831620 (defined @ /home/t.afanasyeva/mambaforge/envs/MATseq/lib/python3.10/site-packages/keras/src/engine/base_layer_utils.py:137) located in device /job:localhost/replica:0/task:0/device:GPU:0 from device /job:localhost/replica:0/task:0/device:CPU:0
 Cf. https://www.tensorflow.org/xla/known_issues#tfvariable_on_a_different_device
2023-08-29 17:06:40.936381: W tensorflow/core/framework/op_kernel.cc:1828] OP_REQUIRES failed at xla_ops.cc:444 : INVALID_ARGUMENT: Trying to access resource Resource-0-at-0x559b1a7b0be0 (defined @ /home/t.afanasyeva/mambaforge/envs/MATseq/lib/python3.10/site-packages/keras/src/engine/base_layer_utils.py:137) located in device /job:localhost/replica:0/task:0/device:GPU:0 from device /job:localhost/replica:0/task:0/device:CPU:0
 Cf. https://www.tensorflow.org/xla/known_issues#tfvariable_on_a_different_device
2023-08-29 17:07:30.847737: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /device:GPU:0 with 13775 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:3b:00.0, compute capability: 7.5
Epoch 1/300
2023-08-29 17:07:46.715370: W tensorflow/core/framework/op_kernel.cc:1828] OP_REQUIRES failed at xla_ops.cc:444 : INVALID_ARGUMENT: Trying to access resource Resource-9-at-0x559b1a8ae8b0 (defined @ /home/t.afanasyeva/mambaforge/envs/MATseq/lib/python3.10/site-packages/keras/src/engine/base_layer_utils.py:137) located in device /job:localhost/replica:0/task:0/device:GPU:0 from device /job:localhost/replica:0/task:0/device:CPU:0
 Cf. https://www.tensorflow.org/xla/known_issues#tfvariable_on_a_different_device
2023-08-29 17:07:46.715450: W tensorflow/core/framework/op_kernel.cc:1828] OP_REQUIRES failed at xla_ops.cc:444 : INVALID_ARGUMENT: Trying to access resource Resource-8-at-0x559b1a8a0360 (defined @ /home/t.afanasyeva/mambaforge/envs/MATseq/lib/python3.10/site-packages/keras/src/engine/base_layer_utils.py:137) located in device /job:localhost/replica:0/task:0/device:GPU:0 from device /job:localhost/replica:0/task:0/device:CPU:0
 Cf. https://www.tensorflow.org/xla/known_issues#tfvariable_on_a_different_device
2023-08-29 17:07:46.715521: I tensorflow/core/framework/local_rendezvous.cc:405] Local rendezvous recv item cancelled. Key hash: 3498698027515867171
2023-08-29 17:07:46.715555: I tensorflow/core/framework/local_rendezvous.cc:405] Local rendezvous recv item cancelled. Key hash: 14268743461844673415
2023-08-29 17:07:46.715574: I tensorflow/core/framework/local_rendezvous.cc:405] Local rendezvous recv item cancelled. Key hash: 5826925339922921157
2023-08-29 17:07:46.715583: W tensorflow/core/framework/op_kernel.cc:1828] OP_REQUIRES failed at xla_ops.cc:444 : INVALID_ARGUMENT: Trying to access resource Resource-7-at-0x559b1a844ef0 (defined @ /home/t.afanasyeva/mambaforge/envs/MATseq/lib/python3.10/site-packages/keras/src/engine/base_layer_utils.py:137) located in device /job:localhost/replica:0/task:0/device:GPU:0 from device /job:localhost/replica:0/task:0/device:CPU:0
 Cf. https://www.tensorflow.org/xla/known_issues#tfvariable_on_a_different_device
2023-08-29 17:07:46.715634: I tensorflow/core/framework/local_rendezvous.cc:405] Local rendezvous recv item cancelled. Key hash: 17499886087757547399
2023-08-29 17:07:46.715659: I tensorflow/core/framework/local_rendezvous.cc:405] Local rendezvous recv item cancelled. Key hash: 10745376870294702285
2023-08-29 17:07:46.715676: I tensorflow/core/framework/local_rendezvous.cc:405] Local rendezvous recv item cancelled. Key hash: 12559774104711919205
2023-08-29 17:07:46.715696: I tensorflow/core/framework/local_rendezvous.cc:405] Local rendezvous recv item cancelled. Key hash: 6531355946136644935
2023-08-29 17:07:46.715712: I tensorflow/core/framework/local_rendezvous.cc:405] Local rendezvous recv item cancelled. Key hash: 2340169675486940707
2023-08-29 17:07:46.715736: I tensorflow/core/framework/local_rendezvous.cc:405] Local rendezvous recv item cancelled. Key hash: 8476623530493763960
2023-08-29 17:07:46.715752: I tensorflow/core/framework/local_rendezvous.cc:405] Local rendezvous recv item cancelled. Key hash: 8720675571197485604
2023-08-29 17:07:46.715768: I tensorflow/core/framework/local_rendezvous.cc:405] Local rendezvous recv item cancelled. Key hash: 16264446178261107928
2023-08-29 17:07:46.715784: I tensorflow/core/framework/local_rendezvous.cc:405] Local rendezvous recv item cancelled. Key hash: 11469251718854600220
2023-08-29 17:07:46.715799: I tensorflow/core/framework/local_rendezvous.cc:405] Local rendezvous recv item cancelled. Key hash: 14850970556316706602
2023-08-29 17:07:46.715813: I tensorflow/core/framework/local_rendezvous.cc:405] Local rendezvous recv item cancelled. Key hash: 5278890927702326000
2023-08-29 17:07:46.715830: I tensorflow/core/framework/local_rendezvous.cc:405] Local rendezvous recv item cancelled. Key hash: 6883043726355332258
2023-08-29 17:07:46.715865: I tensorflow/core/framework/local_rendezvous.cc:405] Local rendezvous recv item cancelled. Key hash: 2124938208753503804
2023-08-29 17:07:46.715875: W tensorflow/core/framework/op_kernel.cc:1828] OP_REQUIRES failed at xla_ops.cc:444 : INVALID_ARGUMENT: Trying to access resource Resource-6-at-0x559b1a834fc0 (defined @ /home/t.afanasyeva/mambaforge/envs/MATseq/lib/python3.10/site-packages/keras/src/engine/base_layer_utils.py:137) located in device /job:localhost/replica:0/task:0/device:GPU:0 from device /job:localhost/replica:0/task:0/device:CPU:0
 Cf. https://www.tensorflow.org/xla/known_issues#tfvariable_on_a_different_device
2023-08-29 17:07:46.715923: W tensorflow/core/framework/op_kernel.cc:1828] OP_REQUIRES failed at xla_ops.cc:444 : INVALID_ARGUMENT: Trying to access resource Resource-3-at-0x559b1a831620 (defined @ /home/t.afanasyeva/mambaforge/envs/MATseq/lib/python3.10/site-packages/keras/src/engine/base_layer_utils.py:137) located in device /job:localhost/replica:0/task:0/device:GPU:0 from device /job:localhost/replica:0/task:0/device:CPU:0
 Cf. https://www.tensorflow.org/xla/known_issues#tfvariable_on_a_different_device
2023-08-29 17:07:46.716151: W tensorflow/core/framework/op_kernel.cc:1828] OP_REQUIRES failed at xla_ops.cc:444 : INVALID_ARGUMENT: Trying to access resource Resource-2-at-0x559b1a831260 (defined @ /home/t.afanasyeva/mambaforge/envs/MATseq/lib/python3.10/site-packages/keras/src/engine/base_layer_utils.py:137) located in device /job:localhost/replica:0/task:0/device:GPU:0 from device /job:localhost/replica:0/task:0/device:CPU:0
 Cf. https://www.tensorflow.org/xla/known_issues#tfvariable_on_a_different_device
2023-08-29 17:07:46.716172: W tensorflow/core/framework/op_kernel.cc:1828] OP_REQUIRES failed at xla_ops.cc:444 : INVALID_ARGUMENT: Trying to access resource Resource-1-at-0x559b1a7e08b0 (defined @ /home/t.afanasyeva/mambaforge/envs/MATseq/lib/python3.10/site-packages/keras/src/engine/base_layer_utils.py:137) located in device /job:localhost/replica:0/task:0/device:GPU:0 from device /job:localhost/replica:0/task:0/device:CPU:0
 Cf. https://www.tensorflow.org/xla/known_issues#tfvariable_on_a_different_device
2023-08-29 17:07:46.716353: W tensorflow/core/framework/op_kernel.cc:1828] OP_REQUIRES failed at xla_ops.cc:444 : INVALID_ARGUMENT: Trying to access resource Resource-0-at-0x559b1a7b0be0 (defined @ /home/t.afanasyeva/mambaforge/envs/MATseq/lib/python3.10/site-packages/keras/src/engine/base_layer_utils.py:137) located in device /job:localhost/replica:0/task:0/device:GPU:0 from device /job:localhost/replica:0/task:0/device:CPU:0
 Cf. https://www.tensorflow.org/xla/known_issues#tfvariable_on_a_different_device
[name: "/device:CPU:0"
device_type: "CPU"
memory_limit: 268435456
locality {
}
incarnation: 14226284162303639654
xla_global_id: -1
, name: "/device:GPU:0"
device_type: "GPU"
memory_limit: 14444920832
locality {
  bus_id: 1
  links {
  }
}
incarnation: 5901469763346741089
physical_device_desc: "device: 0, name: Tesla T4, pci bus id: 0000:3b:00.0, compute capability: 7.5"
xla_global_id: 416903419
]
2023-08-29 17:24:24.476970: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /device:GPU:0 with 13775 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:3b:00.0, compute capability: 7.5
Epoch 1/300
2023-08-29 17:24:59.298292: W tensorflow/core/framework/op_kernel.cc:1828] OP_REQUIRES failed at xla_ops.cc:444 : INVALID_ARGUMENT: Trying to access resource Resource-9-at-0x559b1a8ae8b0 (defined @ /home/t.afanasyeva/mambaforge/envs/MATseq/lib/python3.10/site-packages/keras/src/engine/base_layer_utils.py:137) located in device /job:localhost/replica:0/task:0/device:GPU:0 from device /job:localhost/replica:0/task:0/device:CPU:0
 Cf. https://www.tensorflow.org/xla/known_issues#tfvariable_on_a_different_device
2023-08-29 17:24:59.298362: W tensorflow/core/framework/op_kernel.cc:1828] OP_REQUIRES failed at xla_ops.cc:444 : INVALID_ARGUMENT: Trying to access resource Resource-8-at-0x559b1a8a0360 (defined @ /home/t.afanasyeva/mambaforge/envs/MATseq/lib/python3.10/site-packages/keras/src/engine/base_layer_utils.py:137) located in device /job:localhost/replica:0/task:0/device:GPU:0 from device /job:localhost/replica:0/task:0/device:CPU:0
 Cf. https://www.tensorflow.org/xla/known_issues#tfvariable_on_a_different_device
2023-08-29 17:24:59.298413: I tensorflow/core/framework/local_rendezvous.cc:405] Local rendezvous recv item cancelled. Key hash: 3498698027515867171
2023-08-29 17:24:59.298443: I tensorflow/core/framework/local_rendezvous.cc:405] Local rendezvous recv item cancelled. Key hash: 14268743461844673415
2023-08-29 17:24:59.298454: W tensorflow/core/framework/op_kernel.cc:1828] OP_REQUIRES failed at xla_ops.cc:444 : INVALID_ARGUMENT: Trying to access resource Resource-7-at-0x559b1a844ef0 (defined @ /home/t.afanasyeva/mambaforge/envs/MATseq/lib/python3.10/site-packages/keras/src/engine/base_layer_utils.py:137) located in device /job:localhost/replica:0/task:0/device:GPU:0 from device /job:localhost/replica:0/task:0/device:CPU:0
 Cf. https://www.tensorflow.org/xla/known_issues#tfvariable_on_a_different_device
2023-08-29 17:24:59.298503: I tensorflow/core/framework/local_rendezvous.cc:405] Local rendezvous recv item cancelled. Key hash: 5826925339922921157
2023-08-29 17:24:59.298519: I tensorflow/core/framework/local_rendezvous.cc:405] Local rendezvous recv item cancelled. Key hash: 17499886087757547399
2023-08-29 17:24:59.298532: I tensorflow/core/framework/local_rendezvous.cc:405] Local rendezvous recv item cancelled. Key hash: 10745376870294702285
2023-08-29 17:24:59.298544: I tensorflow/core/framework/local_rendezvous.cc:405] Local rendezvous recv item cancelled. Key hash: 12559774104711919205
2023-08-29 17:24:59.298557: I tensorflow/core/framework/local_rendezvous.cc:405] Local rendezvous recv item cancelled. Key hash: 6531355946136644935
2023-08-29 17:24:59.298570: I tensorflow/core/framework/local_rendezvous.cc:405] Local rendezvous recv item cancelled. Key hash: 2340169675486940707
2023-08-29 17:24:59.298589: I tensorflow/core/framework/local_rendezvous.cc:405] Local rendezvous recv item cancelled. Key hash: 8476623530493763960
2023-08-29 17:24:59.298605: I tensorflow/core/framework/local_rendezvous.cc:405] Local rendezvous recv item cancelled. Key hash: 8720675571197485604
2023-08-29 17:24:59.298618: I tensorflow/core/framework/local_rendezvous.cc:405] Local rendezvous recv item cancelled. Key hash: 16264446178261107928
2023-08-29 17:24:59.298630: I tensorflow/core/framework/local_rendezvous.cc:405] Local rendezvous recv item cancelled. Key hash: 11469251718854600220
2023-08-29 17:24:59.298642: I tensorflow/core/framework/local_rendezvous.cc:405] Local rendezvous recv item cancelled. Key hash: 14850970556316706602
2023-08-29 17:24:59.298654: I tensorflow/core/framework/local_rendezvous.cc:405] Local rendezvous recv item cancelled. Key hash: 5278890927702326000
2023-08-29 17:24:59.298681: I tensorflow/core/framework/local_rendezvous.cc:405] Local rendezvous recv item cancelled. Key hash: 6883043726355332258
2023-08-29 17:24:59.298710: I tensorflow/core/framework/local_rendezvous.cc:405] Local rendezvous recv item cancelled. Key hash: 2124938208753503804
2023-08-29 17:24:59.299010: W tensorflow/core/framework/op_kernel.cc:1828] OP_REQUIRES failed at xla_ops.cc:444 : INVALID_ARGUMENT: Trying to access resource Resource-3-at-0x559b1a831620 (defined @ /home/t.afanasyeva/mambaforge/envs/MATseq/lib/python3.10/site-packages/keras/src/engine/base_layer_utils.py:137) located in device /job:localhost/replica:0/task:0/device:GPU:0 from device /job:localhost/replica:0/task:0/device:CPU:0
 Cf. https://www.tensorflow.org/xla/known_issues#tfvariable_on_a_different_device
2023-08-29 17:24:59.299060: W tensorflow/core/framework/op_kernel.cc:1828] OP_REQUIRES failed at xla_ops.cc:444 : INVALID_ARGUMENT: Trying to access resource Resource-2-at-0x559b1a831260 (defined @ /home/t.afanasyeva/mambaforge/envs/MATseq/lib/python3.10/site-packages/keras/src/engine/base_layer_utils.py:137) located in device /job:localhost/replica:0/task:0/device:GPU:0 from device /job:localhost/replica:0/task:0/device:CPU:0
 Cf. https://www.tensorflow.org/xla/known_issues#tfvariable_on_a_different_device
2023-08-29 17:24:59.299113: W tensorflow/core/framework/op_kernel.cc:1828] OP_REQUIRES failed at xla_ops.cc:444 : INVALID_ARGUMENT: Trying to access resource Resource-6-at-0x559b1a834fc0 (defined @ /home/t.afanasyeva/mambaforge/envs/MATseq/lib/python3.10/site-packages/keras/src/engine/base_layer_utils.py:137) located in device /job:localhost/replica:0/task:0/device:GPU:0 from device /job:localhost/replica:0/task:0/device:CPU:0
 Cf. https://www.tensorflow.org/xla/known_issues#tfvariable_on_a_different_device
2023-08-29 17:24:59.299158: W tensorflow/core/framework/op_kernel.cc:1828] OP_REQUIRES failed at xla_ops.cc:444 : INVALID_ARGUMENT: Trying to access resource Resource-1-at-0x559b1a7e08b0 (defined @ /home/t.afanasyeva/mambaforge/envs/MATseq/lib/python3.10/site-packages/keras/src/engine/base_layer_utils.py:137) located in device /job:localhost/replica:0/task:0/device:GPU:0 from device /job:localhost/replica:0/task:0/device:CPU:0
 Cf. https://www.tensorflow.org/xla/known_issues#tfvariable_on_a_different_device
2023-08-29 17:24:59.299291: W tensorflow/core/framework/op_kernel.cc:1828] OP_REQUIRES failed at xla_ops.cc:444 : INVALID_ARGUMENT: Trying to access resource Resource-0-at-0x559b1a7b0be0 (defined @ /home/t.afanasyeva/mambaforge/envs/MATseq/lib/python3.10/site-packages/keras/src/engine/base_layer_utils.py:137) located in device /job:localhost/replica:0/task:0/device:GPU:0 from device /job:localhost/replica:0/task:0/device:CPU:0
